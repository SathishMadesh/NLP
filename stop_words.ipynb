{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c20168",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''Respected listeners, today I honor Dr. APJ Abdul Kalam, the 'Missile Man of India' and a true inspiration to us all. Born into a humble family in Rameswaram, he rose to become the President of India through sheer hard work, dedication, and a passion for learning. He famously taught us that dreams are not what we see in our sleep, but the things that keep us awake, urging every student to aim high and fear no failure. Dr. Kalam’s life is a perfect example of how simple living and high thinking can change the world. Let us remember his legacy by staying curious, working hard, and serving our nation with the same 'ignited mind' that he always encouraged in the youth. Thank you!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af66b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698ee07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356b70cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e72d7da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['அங்கு',\n",
       " 'அங்கே',\n",
       " 'அடுத்த',\n",
       " 'அதனால்',\n",
       " 'அதன்',\n",
       " 'அதற்கு',\n",
       " 'அதிக',\n",
       " 'அதில்',\n",
       " 'அது',\n",
       " 'அதே',\n",
       " 'அதை',\n",
       " 'அந்த',\n",
       " 'அந்தக்',\n",
       " 'அந்தப்',\n",
       " 'அன்று',\n",
       " 'அல்லது',\n",
       " 'அவன்',\n",
       " 'அவரது',\n",
       " 'அவர்',\n",
       " 'அவர்கள்',\n",
       " 'அவள்',\n",
       " 'அவை',\n",
       " 'ஆகிய',\n",
       " 'ஆகியோர்',\n",
       " 'ஆகும்',\n",
       " 'இங்கு',\n",
       " 'இங்கே',\n",
       " 'இடத்தில்',\n",
       " 'இடம்',\n",
       " 'இதனால்',\n",
       " 'இதனை',\n",
       " 'இதன்',\n",
       " 'இதற்கு',\n",
       " 'இதில்',\n",
       " 'இது',\n",
       " 'இதை',\n",
       " 'இந்த',\n",
       " 'இந்தக்',\n",
       " 'இந்தத்',\n",
       " 'இந்தப்',\n",
       " 'இன்னும்',\n",
       " 'இப்போது',\n",
       " 'இரு',\n",
       " 'இருக்கும்',\n",
       " 'இருந்த',\n",
       " 'இருந்தது',\n",
       " 'இருந்து',\n",
       " 'இவர்',\n",
       " 'இவை',\n",
       " 'உன்',\n",
       " 'உள்ள',\n",
       " 'உள்ளது',\n",
       " 'உள்ளன',\n",
       " 'எந்த',\n",
       " 'என',\n",
       " 'எனக்',\n",
       " 'எனக்கு',\n",
       " 'எனப்படும்',\n",
       " 'எனவும்',\n",
       " 'எனவே',\n",
       " 'எனினும்',\n",
       " 'எனும்',\n",
       " 'என்',\n",
       " 'என்ன',\n",
       " 'என்னும்',\n",
       " 'என்பது',\n",
       " 'என்பதை',\n",
       " 'என்ற',\n",
       " 'என்று',\n",
       " 'என்றும்',\n",
       " 'எல்லாம்',\n",
       " 'ஏன்',\n",
       " 'ஒரு',\n",
       " 'ஒரே',\n",
       " 'ஓர்',\n",
       " 'கொண்ட',\n",
       " 'கொண்டு',\n",
       " 'கொள்ள',\n",
       " 'சற்று',\n",
       " 'சிறு',\n",
       " 'சில',\n",
       " 'சேர்ந்த',\n",
       " 'தனது',\n",
       " 'தன்',\n",
       " 'தவிர',\n",
       " 'தான்',\n",
       " 'நான்',\n",
       " 'நாம்',\n",
       " 'நீ',\n",
       " 'பற்றி',\n",
       " 'பற்றிய',\n",
       " 'பல',\n",
       " 'பலரும்',\n",
       " 'பல்வேறு',\n",
       " 'பின்',\n",
       " 'பின்னர்',\n",
       " 'பிற',\n",
       " 'பிறகு',\n",
       " 'பெரும்',\n",
       " 'பேர்',\n",
       " 'போது',\n",
       " 'போன்ற',\n",
       " 'போல',\n",
       " 'போல்',\n",
       " 'மட்டுமே',\n",
       " 'மட்டும்',\n",
       " 'மற்ற',\n",
       " 'மற்றும்',\n",
       " 'மிக',\n",
       " 'மிகவும்',\n",
       " 'மீது',\n",
       " 'முதல்',\n",
       " 'முறை',\n",
       " 'மேலும்',\n",
       " 'மேல்',\n",
       " 'யார்',\n",
       " 'வந்த',\n",
       " 'வந்து',\n",
       " 'வரும்',\n",
       " 'வரை',\n",
       " 'வரையில்',\n",
       " 'விட',\n",
       " 'விட்டு',\n",
       " 'வேண்டும்',\n",
       " 'வேறு']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('Tamil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94cfb0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "\n",
    "## Sentence Tokenization\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "\n",
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41669b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying stopwords and filter and then apply stemming\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [snowball_stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eea86dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"respect listen , today i honor dr. apj abdul kalam , 'missil man india ' true inspir us .\",\n",
       " 'born humbl famili rameswaram , rose becom presid india sheer hard work , dedic , passion learn .',\n",
       " 'he famous taught us dream see sleep , thing keep us awak , urg everi student aim high fear failur .',\n",
       " 'dr. kalam ’ life perfect exampl simpl live high think chang world .',\n",
       " \"let us rememb legaci stay curiou , work hard , serv nation 'ignit mind ' alway encourag youth .\",\n",
       " 'thank !']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also use Lemmatization instead of Stemming \n",
    "## And it gives better results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
